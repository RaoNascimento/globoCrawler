2018-05-19 21:53:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:53:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:53:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:53:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:53:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:53:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:53:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:53:01 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:53:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:53:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:53:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:53:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:53:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:53:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32274,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 53, 2, 241861),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60846080,
 'memusage/startup': 60846080,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 53, 1, 610173)}
2018-05-19 21:53:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:53:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:53:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:53:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:53:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:53:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:53:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:53:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:53:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:53:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:53:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:53:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:53:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:53:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41228,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 53, 3, 58864),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61005824,
 'memusage/startup': 61005824,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 53, 2, 786810)}
2018-05-19 21:53:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:53:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:53:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:53:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:53:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:53:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:53:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:53:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:53:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:53:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:53:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:53:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:53:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:53:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:53:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27913,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 53, 4, 50625),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60882944,
 'memusage/startup': 60882944,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 53, 3, 519316)}
2018-05-19 21:53:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...


Fim escrita no arquivo de links...

2018-05-19 21:53:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:53:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:53:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:53:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:53:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:53:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:53:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:53:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:53:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:53:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:53:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:53:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:53:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45865,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 53, 4, 901286),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60862464,
 'memusage/startup': 60862464,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 53, 4, 547457)}
2018-05-19 21:53:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:54:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:54:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:54:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:54:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:54:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:54:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:54:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:54:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:54:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:54:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:54:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:54:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:54:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:54:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32282,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 54, 2, 785034),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60825600,
 'memusage/startup': 60825600,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 54, 2, 415038)}
2018-05-19 21:54:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:54:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:54:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:54:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:54:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:54:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:54:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:54:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:54:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:54:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:54:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:54:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:54:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:54:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41228,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 54, 3, 582365),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60993536,
 'memusage/startup': 60993536,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 54, 3, 312494)}
2018-05-19 21:54:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:54:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:54:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:54:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:54:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:54:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:54:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:54:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:54:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:54:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27920,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 54, 4, 448940),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61116416,
 'memusage/startup': 61116416,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 54, 4, 76098)}
2018-05-19 21:54:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:54:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:54:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:54:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:54:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:54:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:54:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:54:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:54:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:54:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45865,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 54, 5, 227855),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61026304,
 'memusage/startup': 61026304,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 54, 4, 982981)}
2018-05-19 21:54:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:55:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:55:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:55:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:55:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:55:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:55:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:55:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:55:01 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:55:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:55:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:55:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:55:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:55:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32291,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 55, 2, 220191),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60870656,
 'memusage/startup': 60870656,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 55, 1, 758230)}
2018-05-19 21:55:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:55:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:55:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:55:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:55:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:55:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:55:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:55:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:55:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:55:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:55:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:55:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:55:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41236,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 55, 2, 964965),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60895232,
 'memusage/startup': 60895232,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 55, 2, 709343)}
2018-05-19 21:55:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:55:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:55:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:55:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:55:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:55:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:55:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:55:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:55:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:55:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:55:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:55:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:55:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:55:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:55:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27929,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 55, 4, 13960),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60846080,
 'memusage/startup': 60846080,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 55, 3, 449353)}
2018-05-19 21:55:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:55:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:55:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:55:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:55:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:55:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:55:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:55:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:55:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:55:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:55:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:55:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:55:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45873,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 55, 4, 879476),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61022208,
 'memusage/startup': 61022208,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 55, 4, 512879)}
2018-05-19 21:55:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:56:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:56:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:56:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:56:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:56:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:56:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:56:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:56:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:56:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:56:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:56:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:56:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:56:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:56:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 56, 2, 834120),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61042688,
 'memusage/startup': 61042688,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 56, 2, 401776)}
2018-05-19 21:56:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:56:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:56:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:56:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:56:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:56:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:56:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:56:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:56:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:56:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:56:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:56:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:56:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:56:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41227,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 56, 3, 639431),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61001728,
 'memusage/startup': 61001728,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 56, 3, 358078)}
2018-05-19 21:56:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:56:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:56:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:56:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:56:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:56:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:56:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:56:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:56:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:56:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:56:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:56:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:56:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:56:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:56:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27921,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 56, 4, 505677),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60846080,
 'memusage/startup': 60846080,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 56, 4, 134885)}
2018-05-19 21:56:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:56:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:56:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:56:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:56:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:56:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:56:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:56:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:56:05 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:56:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:56:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:56:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:56:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:56:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45865,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 56, 5, 346193),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61005824,
 'memusage/startup': 61005824,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 56, 5, 70678)}
2018-05-19 21:56:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:57:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:57:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:57:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:57:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:57:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:57:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:57:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:57:01 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:57:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:57:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:57:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:57:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:57:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:57:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 57, 2, 417396),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61026304,
 'memusage/startup': 61026304,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 57, 1, 871848)}
2018-05-19 21:57:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:57:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:57:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:57:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:57:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:57:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:57:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:57:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:57:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:57:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:57:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:57:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:57:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:57:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41227,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 57, 3, 341198),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61026304,
 'memusage/startup': 61026304,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 57, 2, 954487)}
2018-05-19 21:57:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:57:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:57:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:57:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:57:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:57:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:57:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:57:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:57:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:57:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:57:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:57:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:57:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:57:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:57:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27921,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 57, 4, 356372),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60837888,
 'memusage/startup': 60837888,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 57, 3, 860231)}
2018-05-19 21:57:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:57:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:57:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:57:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:57:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:57:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:57:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:57:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:57:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:57:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:57:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:57:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:57:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:57:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45873,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 57, 5, 168828),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61018112,
 'memusage/startup': 61018112,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 57, 4, 884696)}
2018-05-19 21:57:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:58:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:58:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:58:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:58:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:58:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:58:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:58:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:58:01 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:58:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:58:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:58:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:58:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:58:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:58:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32291,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 58, 2, 166694),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60776448,
 'memusage/startup': 60776448,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 58, 1, 696924)}
2018-05-19 21:58:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:58:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:58:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:58:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:58:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:58:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:58:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:58:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:58:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:58:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:58:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:58:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:58:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:58:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41235,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 58, 2, 985225),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60891136,
 'memusage/startup': 60891136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 58, 2, 710650)}
2018-05-19 21:58:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:58:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:58:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:58:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:58:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:58:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:58:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:58:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:58:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:58:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:58:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:58:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:58:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:58:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:58:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27929,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 58, 3, 893155),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61034496,
 'memusage/startup': 61034496,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 58, 3, 498464)}
2018-05-19 21:58:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:58:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:58:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:58:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:58:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:58:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:58:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:58:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:58:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:58:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:58:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:58:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:58:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:58:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45865,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 58, 4, 711498),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60817408,
 'memusage/startup': 60817408,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 58, 4, 444870)}
2018-05-19 21:58:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-19 21:59:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:59:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:59:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:59:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:59:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:59:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:59:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:59:02 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:59:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:59:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:59:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-19 21:59:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:59:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:59:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 59, 2, 589521),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61022208,
 'memusage/startup': 61022208,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 59, 2, 232162)}
2018-05-19 21:59:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-19 21:59:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:59:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:59:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:59:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:59:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:59:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:59:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:59:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41227,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 59, 3, 310385),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60776448,
 'memusage/startup': 60776448,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 59, 3, 33798)}
2018-05-19 21:59:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-19 21:59:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:59:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:59:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:59:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:59:03 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:59:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:59:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:59:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-19 21:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:59:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:59:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27922,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 59, 4, 348427),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61157376,
 'memusage/startup': 61157376,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 0, 59, 3, 823062)}
2018-05-19 21:59:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/psdb-acha-que-moro-sera-implacavel-com-richa/')

Fim escrita no arquivo de links...

2018-05-19 21:59:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-19 21:59:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-19 21:59:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-19 21:59:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-19 21:59:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-19 21:59:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-19 21:59:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-19 21:59:04 [scrapy.core.engine] INFO: Spider opened
2018-05-19 21:59:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-19 21:59:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-19 21:59:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-19 21:59:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-19 21:59:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45865,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 0, 59, 5, 237115),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61149184,
 'memusage/startup': 61149184,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 0, 59, 4, 890096)}
2018-05-19 21:59:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/ao-premiar-morte-com-flores-governador-de-sp-faz-um-desservico-a-policia/')

Fim escrita no arquivo de links...

2018-05-20 13:46:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:46:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:46:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:46:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:46:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:46:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:46:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:46:09 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:46:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:46:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:46:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:46:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:46:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 46, 10, 212811),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60641280,
 'memusage/startup': 60641280,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 46, 9, 262796)}
2018-05-20 13:46:10 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:46:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:46:10 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:46:10 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:46:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:46:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:46:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:46:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:46:10 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:46:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:46:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:46:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:46:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:46:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41288,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 46, 11, 51309),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61407232,
 'memusage/startup': 61407232,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 46, 10, 738056)}
2018-05-20 13:46:11 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:46:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:46:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:46:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:46:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:46:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:46:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:46:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:46:11 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:46:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:46:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:46:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:46:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:46:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:46:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 46, 12, 3059),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60833792,
 'memusage/startup': 60833792,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 46, 11, 540613)}
2018-05-20 13:46:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:46:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:46:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:46:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:46:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:46:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:46:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:46:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:46:12 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:46:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:46:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:46:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:46:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:46:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 46, 12, 792088),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61009920,
 'memusage/startup': 61009920,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 46, 12, 508202)}
2018-05-20 13:46:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:47:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:47:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:47:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:47:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:47:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:47:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:47:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:47:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:47:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:47:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:47:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:47:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:47:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:47:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32291,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 47, 2, 700951),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61038592,
 'memusage/startup': 61038592,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 47, 2, 279509)}
2018-05-20 13:47:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:47:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:47:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:47:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:47:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:47:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:47:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:47:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:47:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:47:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41296,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 47, 3, 531093),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60870656,
 'memusage/startup': 60870656,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 47, 3, 248515)}
2018-05-20 13:47:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:47:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:47:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:47:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:47:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:47:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:47:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:47:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:47:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:47:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:47:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:47:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29831,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 47, 4, 394662),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60887040,
 'memusage/startup': 60887040,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 47, 4, 1352)}
2018-05-20 13:47:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:47:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:47:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:47:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:47:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:47:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:47:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:47:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:47:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:47:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:47:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:47:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:47:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:47:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45958,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 47, 5, 140488),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61140992,
 'memusage/startup': 61140992,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 47, 4, 860842)}
2018-05-20 13:47:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:48:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:48:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:48:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:48:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:48:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:48:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:48:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:48:01 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:48:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:48:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:48:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:48:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:48:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:48:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 48, 2, 243392),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61022208,
 'memusage/startup': 61022208,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 48, 1, 683996)}
2018-05-20 13:48:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:48:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:48:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:48:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:48:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:48:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:48:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:48:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:48:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:48:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:48:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:48:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:48:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:48:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 48, 3, 137240),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61018112,
 'memusage/startup': 61018112,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 48, 2, 795619)}
2018-05-20 13:48:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:48:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:48:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:48:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:48:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:48:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:48:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:48:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:48:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:48:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:48:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:48:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:48:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:48:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:48:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29826,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 48, 4, 56448),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60837888,
 'memusage/startup': 60837888,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 48, 3, 592505)}
2018-05-20 13:48:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:48:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:48:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:48:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:48:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:48:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:48:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:48:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:48:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:48:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:48:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:48:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:48:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:48:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 48, 4, 895963),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60862464,
 'memusage/startup': 60862464,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 48, 4, 589004)}
2018-05-20 13:48:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:49:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:49:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:49:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:49:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:49:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:49:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:49:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:49:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:49:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:49:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:49:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:49:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:49:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:49:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 49, 2, 858123),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60764160,
 'memusage/startup': 60764160,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 49, 2, 408858)}
2018-05-20 13:49:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:49:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:49:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:49:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:49:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:49:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:49:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:49:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:49:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:49:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:49:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:49:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:49:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:49:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 49, 3, 708600),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60862464,
 'memusage/startup': 60862464,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 49, 3, 403270)}
2018-05-20 13:49:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:49:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:49:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:49:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:49:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:49:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:49:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:49:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:49:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:49:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:49:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:49:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:49:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:49:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:49:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29826,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 49, 4, 656081),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60813312,
 'memusage/startup': 60813312,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 49, 4, 221988)}
2018-05-20 13:49:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:49:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:49:05 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:49:05 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:49:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:49:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:49:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:49:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:49:05 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:49:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:49:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:49:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:49:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:49:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 49, 5, 723412),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61128704,
 'memusage/startup': 61128704,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 49, 5, 210176)}
2018-05-20 13:49:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:50:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:50:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:50:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:50:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:50:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:50:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:50:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:50:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:50:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:50:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:50:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:50:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:50:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:50:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 50, 2, 684417),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61038592,
 'memusage/startup': 61038592,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 50, 2, 250589)}
2018-05-20 13:50:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:50:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:50:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:50:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:50:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:50:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:50:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:50:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:50:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:50:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 50, 3, 490943),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60784640,
 'memusage/startup': 60784640,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 50, 3, 203007)}
2018-05-20 13:50:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:50:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:50:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:50:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:50:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:50:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:50:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:50:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:50:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:50:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:50:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:50:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29827,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 50, 4, 352118),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61149184,
 'memusage/startup': 61149184,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 50, 3, 917557)}
2018-05-20 13:50:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:50:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:50:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:50:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:50:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:50:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:50:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:50:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:50:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:50:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:50:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:50:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:50:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:50:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45958,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 50, 5, 146255),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61399040,
 'memusage/startup': 61399040,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 50, 4, 891144)}
2018-05-20 13:50:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:51:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:51:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:51:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:51:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:51:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:51:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:51:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:51:01 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:51:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:51:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:51:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:51:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:51:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:51:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32291,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 51, 2, 46965),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61149184,
 'memusage/startup': 61149184,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 51, 1, 638619)}
2018-05-20 13:51:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:51:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:51:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:51:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:51:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:51:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:51:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:51:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:51:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:51:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:51:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:51:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:51:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:51:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41298,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 51, 2, 812389),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61001728,
 'memusage/startup': 61001728,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 51, 2, 548504)}
2018-05-20 13:51:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:51:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:51:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:51:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:51:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:51:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:51:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:51:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:51:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:51:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:51:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:51:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:51:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:51:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:51:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29835,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 51, 3, 708185),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61026304,
 'memusage/startup': 61026304,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 51, 3, 299653)}
2018-05-20 13:51:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:51:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:51:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:51:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:51:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:51:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:51:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:51:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:51:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:51:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:51:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:51:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:51:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:51:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 51, 4, 576400),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60751872,
 'memusage/startup': 60751872,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 51, 4, 275043)}
2018-05-20 13:51:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:52:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:52:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:52:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:52:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:52:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:52:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:52:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:52:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:52:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:52:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:52:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:52:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:52:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:52:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 52, 2, 776086),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61145088,
 'memusage/startup': 61145088,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 52, 2, 96224)}
2018-05-20 13:52:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:52:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:52:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:52:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:52:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:52:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:52:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:52:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:52:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:52:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:52:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:52:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:52:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:52:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 52, 3, 651044),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61026304,
 'memusage/startup': 61026304,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 52, 3, 343281)}
2018-05-20 13:52:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:52:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:52:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:52:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:52:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:52:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:52:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:52:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:52:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:52:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:52:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:52:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:52:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:52:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:52:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29827,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 52, 4, 624162),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60772352,
 'memusage/startup': 60772352,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 52, 4, 159682)}
2018-05-20 13:52:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:52:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:52:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:52:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:52:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:52:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:52:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:52:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:52:05 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:52:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:52:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:52:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:52:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:52:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 52, 5, 444298),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61001728,
 'memusage/startup': 61001728,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 52, 5, 142038)}
2018-05-20 13:52:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:53:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:53:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:53:01 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:53:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:53:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:53:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:53:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:53:01 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:53:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:53:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:53:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:53:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:53:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:53:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 53, 2, 424281),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60813312,
 'memusage/startup': 60813312,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 53, 1, 964819)}
2018-05-20 13:53:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:53:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:53:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:53:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:53:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:53:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:53:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:53:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:53:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:53:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:53:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:53:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:53:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:53:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41291,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 53, 3, 298850),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61038592,
 'memusage/startup': 61038592,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 53, 2, 971400)}
2018-05-20 13:53:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:53:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:53:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:53:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:53:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:53:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:53:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:53:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:53:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:53:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:53:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:53:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:53:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:53:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:53:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29827,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 53, 4, 225755),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60809216,
 'memusage/startup': 60809216,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 53, 3, 803890)}
2018-05-20 13:53:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:53:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:53:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:53:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:53:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:53:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:53:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:53:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:53:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:53:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:53:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:53:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:53:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:53:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45958,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 53, 5, 30316),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61403136,
 'memusage/startup': 61403136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 53, 4, 763952)}
2018-05-20 13:53:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:57:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:57:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:57:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:57:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:57:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:57:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:57:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:57:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:57:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:57:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:57:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:57:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:57:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:57:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 57, 2, 929492),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60887040,
 'memusage/startup': 60887040,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 57, 2, 450479)}
2018-05-20 13:57:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:57:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:57:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:57:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:57:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:57:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:57:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:57:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:57:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:57:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:57:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:57:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:57:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:57:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 57, 3, 776185),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60850176,
 'memusage/startup': 60850176,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 57, 3, 472474)}
2018-05-20 13:57:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:57:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:57:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:57:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:57:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:57:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:57:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:57:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:57:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:57:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:57:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:57:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:57:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:57:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:57:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29824,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 57, 4, 710091),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61140992,
 'memusage/startup': 61140992,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 57, 4, 266526)}
2018-05-20 13:57:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:57:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:57:05 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:57:05 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:57:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:57:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:57:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:57:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:57:05 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:57:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:57:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:57:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:57:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:57:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 57, 5, 797896),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61153280,
 'memusage/startup': 61153280,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 57, 5, 260400)}
2018-05-20 13:57:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-20 13:58:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:58:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:58:02 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:58:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:58:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:58:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:58:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:58:02 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:58:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:58:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:58:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://brasilianismo.blogosfera.uol.com.br/> from <GET https://brasilianismo.blogosfera.uol.com.br/>
2018-05-20 13:58:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://brasilianismo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:58:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:58:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 32283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 58, 2, 738002),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 61030400,
 'memusage/startup': 61030400,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 58, 2, 284354)}
2018-05-20 13:58:02 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/17/sem-candidato-forte-mercado-se-preocupa-com-eleicao-e-flerta-com-bolsonaro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/16/luta-contra-a-corrupcao-se-torna-um-trunfo-do-soft-power-brasileiro/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/14/repercussao-mundial-sobre-pm-que-matou-ladrao-expoe-violencia-do-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/escola-sem-partido-ameaca-relacoes-academicas-do-brasil-com-o-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/09/estudos-brasileiros-nos-eua-em-tempos-de-crise-anos-1960-70-e-hoje/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/08/com-crise-e-corrupcao-agencia-ve-fim-de-tabu-sobre-privatizacao-no-brasil/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/07/crise-politica-faz-brasil-buscar-versao-tropical-de-macron-diz-le-monde/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/04/mudanca-no-foro-privilegiado-leva-medo-ao-congresso-diz-financial-times/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/05/02/decadencia-da-imagem-do-brasil-e-drastica-diz-noam-chomsky/')
('Link j\xc3\xa1 coletado: ', 'https://brasilianismo.blogosfera.uol.com.br/2018/04/30/violencia-politica-para-de-chocar-e-parece-ter-virado-algo-normal-no-brasil/')

Fim escrita no arquivo de links...

2018-05-20 13:58:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:58:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:58:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:58:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:58:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:58:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:58:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:58:03 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:58:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:58:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:58:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://carlosmelo.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:58:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:58:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 247,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 41290,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 58, 3, 584969),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 61140992,
 'memusage/startup': 61140992,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 58, 3, 277666)}
2018-05-20 13:58:03 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/16/dificil-situacao-de-geraldo-alckmin/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/15/mais-dificil-sera-governar/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/08/joaquim-barbosa-e-o-nao-fato-politico/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/06/a-prisao-de-lula-e-o-quixotismo-do-pt/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/04/sinais-importantes/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/05/02/a-banalizacao-do-mal/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/27/joaquim-barbosa-acelera-a-eleicao/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/25/a-entrevista-de-jose-dirceu/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/19/o-psdb-e-o-mundo-vasto-mundo/')
('Link j\xc3\xa1 coletado: ', 'https://carlosmelo.blogosfera.uol.com.br/2018/04/17/o-desafio-de-joaquim-barbosa/')

Fim escrita no arquivo de links...

2018-05-20 13:58:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:58:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:58:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:58:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:58:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:58:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:58:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:58:04 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:58:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:58:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:58:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://josiasdesouza.blogosfera.uol.com.br/> from <GET https://josiasdesouza.blogosfera.uol.com.br/>
2018-05-20 13:58:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://josiasdesouza.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:58:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:58:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 500,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29824,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 58, 4, 515478),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'memusage/max': 60764160,
 'memusage/startup': 60764160,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 5, 20, 16, 58, 4, 45431)}
2018-05-20 13:58:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/20/novo-pacote-anticorrupcao-quer-mudar-sistematica-de-indicacoes-para-o-stf/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/depoimento-da-filha-de-temer-a-pf-e-gelatinoso/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/herdeiro-de-jose-alencar-entra-no-jogo-de-2018/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/gilmar-solta-mais-4-que-bretas-mandara-prender/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/tecnicamente-o-pt-virou-organizacao-criminosa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/19/popularidade-2/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/retirar-carros-e-assessores-ameaca-a-subsistencia-de-lula-sustenta-defesa/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/prisao-de-jose-dirceu-ganhou-ar-de-normalidade/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/temer-precisamos-de-um-unico-nome-de-centro/')
('Link j\xc3\xa1 coletado: ', 'https://josiasdesouza.blogosfera.uol.com.br/2018/05/18/dirceu-atual-faz-do-dirceu-de-1968-uma-alegoria/')

Fim escrita no arquivo de links...

2018-05-20 13:58:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-20 13:58:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 16.0.0, Python 2.7.12 (default, Dec  4 2017, 14:50:18) - [GCC 5.4.0 20160609], pyOpenSSL 0.15.1 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 1.2.3, Platform Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
2018-05-20 13:58:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-20 13:58:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-20 13:58:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-20 13:58:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-20 13:58:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-20 13:58:05 [scrapy.core.engine] INFO: Spider opened
2018-05-20 13:58:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-20 13:58:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-20 13:58:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://blogdosakamoto.blogosfera.uol.com.br/> (referer: None)
2018-05-20 13:58:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-20 13:58:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 45950,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 20, 16, 58, 5, 320907),
 'log_count/DEBUG': 2,
 'log_count/INFO': 7,
 'memusage/max': 60801024,
 'memusage/startup': 60801024,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 5, 20, 16, 58, 5, 7739)}
2018-05-20 13:58:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...


Escrevendo no arquivo de links...

('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/19/vendo-harry-e-meghan-deu-vontade-de-ter-um-rei-no-brasil-jose-mujica/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/chefe-do-combate-a-escravidao-revela-falta-de-recursos-e-pode-ser-demitida/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/18/brasil-nao-tem-pressa-para-tirar-idosos-pobres-da-prisao-do-analfabetismo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/noticia-falsa-diz-que-terei-o-poder-de-censurar-noticia-falsa-no-facebook/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/quase-28-milhoes-de-brasileiros-gritam-que-o-tema-da-eleicao-sera-emprego/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/17/a-montanha-de-jovens-negros-mortos-e-prova-de-nosso-fracasso-como-pais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/mesmo-na-lista-suja-da-escravidao-cutrale-recebe-selo-de-boas-praticas/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/16/ocupacoes-crescem-com-desemprego-mas-governo-temer-diz-que-esta-tudo-lindo/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/15/o-caso-da-pm-e-do-ladrao-voce-tambem-comenta-sem-ler-nas-redes-sociais/')
('Link j\xc3\xa1 coletado: ', 'https://blogdosakamoto.blogosfera.uol.com.br/2018/05/14/o-brasil-voltou-20-anos-em-2-exceto-pela-virgula-o-governo-tem-razao/')

Fim escrita no arquivo de links...

2018-05-21 07:00:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:00:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:00:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:00:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:00:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:00:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:00:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:00:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:00:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:00:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:00:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:00:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:01:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:01:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:01:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:01:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:01:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:01:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:01:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:01:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:01:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:01:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:01:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:01:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:01:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:01:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:01:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 1, 9, 835284),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33579008,
 'memusage/startup': 32542720,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 0, 8, 812412)}
2018-05-21 07:01:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:01:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:01:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:01:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:01:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:01:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:01:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:01:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:01:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:01:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:01:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:01:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:01:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:01:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:01:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:02:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:02:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:02:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:02:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:02:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:02:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:02:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:02:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:02:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:02:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:02:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:02:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:02:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:02:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:02:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 2, 6, 74490),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33140736,
 'memusage/startup': 32526336,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 1, 5, 413132)}
2018-05-21 07:02:06 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:02:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:02:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:02:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:02:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:02:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:02:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:02:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:02:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:02:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:02:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:02:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:02:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:02:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:02:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:02:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 2, 14, 57517),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33480704,
 'memusage/startup': 32870400,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 1, 13, 578085)}
2018-05-21 07:02:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:02:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:02:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:02:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:02:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:02:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:02:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:02:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:02:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:02:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:02:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:02:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:02:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:02:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:02:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:02:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:02:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:03:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:03:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:03:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:03:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:03:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:03:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:03:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:03:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:03:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:03:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:03:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:03:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:03:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 3, 4, 883916),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33497088,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 2, 4, 233069)}
2018-05-21 07:03:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:03:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:03:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:03:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:03:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:03:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:03:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:03:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:03:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:03:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:03:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:03:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:03:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:03:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 3, 9, 704497),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33501184,
 'memusage/startup': 32890880,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 2, 9, 195259)}
2018-05-21 07:03:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:03:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:03:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:03:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:03:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:03:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:03:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:03:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:03:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:03:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:03:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:03:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:03:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:03:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 3, 17, 882197),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33423360,
 'memusage/startup': 32432128,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 2, 17, 267532)}
2018-05-21 07:03:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:03:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:03:20 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:03:20 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:03:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:03:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:03:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:03:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:03:21 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:03:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:03:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:03:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:03:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:03:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:03:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:03:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:03:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:03:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:04:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:04:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:04:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:04:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:04:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:04:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:04:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:04:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:04:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:04:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:04:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:04:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:04:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:04:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 4, 5, 273869),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33488896,
 'memusage/startup': 32739328,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 3, 4, 670979)}
2018-05-21 07:04:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:04:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:04:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:04:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:04:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:04:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:04:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:04:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:04:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:04:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:04:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:04:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:04:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:04:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 4, 8, 896482),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33128448,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 3, 8, 399616)}
2018-05-21 07:04:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:04:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:04:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:04:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:04:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:04:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:04:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:04:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:04:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:04:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:04:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:04:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:04:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:04:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 4, 13, 807860),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33570816,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 3, 13, 215897)}
2018-05-21 07:04:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:04:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:04:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:04:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:04:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:04:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:04:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:04:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:04:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:04:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:04:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:04:21 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:04:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:04:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:04:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 4, 21, 666711),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33251328,
 'memusage/startup': 32608256,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 3, 21, 189461)}
2018-05-21 07:04:21 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:04:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:04:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:04:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:04:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:04:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:04:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:04:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:04:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:05:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:05:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:05:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:05:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:05:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:05:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:05:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:05:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:05:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:05:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:05:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:05:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:05:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 5, 5, 74179),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33677312,
 'memusage/startup': 32927744,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 4, 4, 444430)}
2018-05-21 07:05:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:05:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:05:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:05:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:05:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:05:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:05:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:05:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:05:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:05:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:05:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:05:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:05:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:05:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 5, 9, 21686),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33484800,
 'memusage/startup': 32870400,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 4, 8, 473030)}
2018-05-21 07:05:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:05:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:05:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:05:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:05:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:05:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:05:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:05:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:05:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:05:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:05:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:05:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:05:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:05:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 5, 12, 753408),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33665024,
 'memusage/startup': 32608256,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 4, 12, 116327)}
2018-05-21 07:05:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:05:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:05:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:05:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:05:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:05:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:05:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:05:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:05:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:05:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:05:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:05:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:05:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:05:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 5, 17, 584570),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33042432,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 4, 17, 117494)}
2018-05-21 07:05:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:05:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:05:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:05:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:05:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:05:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:05:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:05:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:05:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:06:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:06:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:06:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:06:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:06:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:06:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:06:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:06:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:06:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:06:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:06:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:06:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:06:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 6, 5, 817062),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33079296,
 'memusage/startup': 32526336,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 5, 5, 37306)}
2018-05-21 07:06:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:06:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:06:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:06:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:06:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:06:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:06:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:06:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:06:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:06:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:06:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:06:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:06:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:06:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 6, 9, 271749),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33128448,
 'memusage/startup': 32509952,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 5, 8, 757914)}
2018-05-21 07:06:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:06:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:06:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:06:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:06:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:06:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:06:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:06:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:06:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:06:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:06:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:06:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:06:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:06:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 6, 13, 145622),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33923072,
 'memusage/startup': 32911360,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 5, 12, 547820)}
2018-05-21 07:06:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:06:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:06:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:06:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:06:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:06:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:06:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:06:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:06:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:06:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:06:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:06:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:06:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:06:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:06:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 6, 16, 521488),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33079296,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 5, 16, 40514)}
2018-05-21 07:06:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:06:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:06:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:06:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:06:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:06:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:06:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:06:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:07:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:07:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:07:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:07:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:07:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:07:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:07:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:07:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:07:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:07:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:07:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:07:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:07:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 7, 5, 391640),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33103872,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 6, 4, 810037)}
2018-05-21 07:07:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:07:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:07:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:07:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:07:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:07:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:07:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:07:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:07:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:07:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:07:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:07:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:07:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:07:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 7, 9, 516707),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33292288,
 'memusage/startup': 32591872,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 6, 9, 28343)}
2018-05-21 07:07:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:07:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:07:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:07:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:07:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:07:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:07:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:07:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:07:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 7, 13, 133256),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33660928,
 'memusage/startup': 32616448,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 6, 12, 540828)}
2018-05-21 07:07:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:07:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:07:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:07:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:07:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:07:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:07:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:07:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:07:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:07:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:07:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:07:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:07:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:07:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:07:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:07:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:07:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:07:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:07:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:07:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 7, 16, 932304),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33103872,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 6, 16, 401628)}
2018-05-21 07:07:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:07:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:07:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:07:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:07:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:07:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:07:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:07:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:07:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:08:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:08:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:08:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:08:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:08:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:08:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:08:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:08:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:08:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:08:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:08:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:08:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:08:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 8, 5, 424723),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 34017280,
 'memusage/startup': 32952320,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 7, 4, 852563)}
2018-05-21 07:08:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:08:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:08:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:08:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:08:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:08:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:08:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:08:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:08:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:08:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:08:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:08:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:08:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:08:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 8, 9, 282158),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33067008,
 'memusage/startup': 32473088,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 7, 8, 786684)}
2018-05-21 07:08:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:08:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:08:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:08:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:08:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:08:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:08:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:08:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:08:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:08:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:08:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:08:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:08:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:08:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 8, 14, 203844),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33705984,
 'memusage/startup': 32673792,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 7, 13, 401663)}
2018-05-21 07:08:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:08:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:08:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:08:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:08:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:08:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:08:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:08:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:08:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 8, 17, 223897),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33497088,
 'memusage/startup': 32886784,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 7, 16, 743112)}
2018-05-21 07:08:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:08:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:08:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:08:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:08:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:08:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:08:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:08:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:08:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:08:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:08:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:08:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:08:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:08:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:09:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:09:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:09:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:09:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:09:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:09:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:09:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:09:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:09:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:09:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:09:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:09:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:09:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 9, 4, 850298),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33472512,
 'memusage/startup': 32444416,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 8, 4, 258862)}
2018-05-21 07:09:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:09:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:09:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:09:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:09:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:09:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:09:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:09:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:09:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:09:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:09:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:09:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:09:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:09:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 9, 8, 989058),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33030144,
 'memusage/startup': 32432128,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 8, 8, 519350)}
2018-05-21 07:09:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:09:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:09:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:09:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:09:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:09:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:09:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:09:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:09:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:09:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:09:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:09:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:09:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:09:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 9, 13, 142508),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33492992,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 8, 12, 470728)}
2018-05-21 07:09:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:09:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:09:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:09:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:09:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:09:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:09:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:09:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:09:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:09:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:09:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:09:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:09:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 9, 17, 977559),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33492992,
 'memusage/startup': 32878592,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 8, 17, 418309)}
2018-05-21 07:09:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:09:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:09:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:09:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:09:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:09:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:09:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:09:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:10:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:10:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:10:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:10:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:10:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:10:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:10:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:10:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:10:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:10:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:10:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:10:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:10:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 10, 5, 475235),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33566720,
 'memusage/startup': 32485376,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 9, 4, 755375)}
2018-05-21 07:10:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:10:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:10:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:10:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:10:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:10:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:10:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:10:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:10:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:10:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:10:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:10:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:10:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:10:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 10, 8, 929474),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33120256,
 'memusage/startup': 32505856,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 9, 8, 459400)}
2018-05-21 07:10:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:10:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:10:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:10:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:10:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:10:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:10:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:10:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:10:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:10:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:10:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:10:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:10:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:10:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 10, 13, 481355),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33525760,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 9, 12, 693468)}
2018-05-21 07:10:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:10:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:10:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:10:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:10:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:10:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:10:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:10:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:10:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:10:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:10:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:10:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:10:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:10:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:10:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 10, 16, 899191),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33021952,
 'memusage/startup': 32432128,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 9, 16, 429216)}
2018-05-21 07:10:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:10:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:10:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:10:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:10:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:10:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:10:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:10:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:10:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:11:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:11:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:11:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:11:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:11:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:11:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:11:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:11:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:11:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:11:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:11:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:11:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:11:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 11, 4, 817171),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33275904,
 'memusage/startup': 32632832,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 10, 4, 246943)}
2018-05-21 07:11:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:11:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:11:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:11:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:11:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:11:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:11:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:11:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:11:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:11:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:11:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:11:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:11:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:11:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 11, 9, 94950),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33095680,
 'memusage/startup': 32485376,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 10, 8, 616442)}
2018-05-21 07:11:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:11:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:11:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:11:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:11:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:11:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:11:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:11:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:11:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 11, 12, 736200),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33673216,
 'memusage/startup': 32546816,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 10, 12, 141475)}
2018-05-21 07:11:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:11:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:11:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:11:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:11:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:11:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:11:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:11:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:11:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:11:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:11:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:11:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:11:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:11:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:11:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:11:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:11:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:11:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:11:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:11:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:11:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 11, 17, 61612),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33353728,
 'memusage/startup': 32747520,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 10, 16, 594264)}
2018-05-21 07:11:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:11:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:11:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:11:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:11:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:11:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:11:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:11:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:11:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:12:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:12:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:12:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:12:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:12:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:12:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:12:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:12:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:12:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:12:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:12:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:12:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 12, 4, 785715),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33804288,
 'memusage/startup': 32731136,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 11, 4, 195232)}
2018-05-21 07:12:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:12:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:12:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:12:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:12:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:12:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:12:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:12:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:12:07 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:12:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:12:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:12:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:12:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:12:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 12, 8, 707477),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33054720,
 'memusage/startup': 32460800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 11, 8, 222968)}
2018-05-21 07:12:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:12:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:12:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:12:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:12:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:12:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:12:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:12:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:12:11 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:12:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:12:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:12:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:12:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:12:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 12, 13, 903209),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32526336,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 11, 13, 39231)}
2018-05-21 07:12:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:12:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:12:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:12:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:12:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:12:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:12:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:12:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:12:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 12, 16, 812708),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33050624,
 'memusage/startup': 32452608,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 11, 16, 323480)}
2018-05-21 07:12:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:12:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:12:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:12:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:12:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:12:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:12:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:12:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:12:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:12:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:12:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:12:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:12:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:12:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:12:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:13:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:13:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:13:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:13:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:13:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:13:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:13:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:13:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:13:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:13:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:13:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:13:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:13:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 13, 4, 932242),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33574912,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 12, 4, 356314)}
2018-05-21 07:13:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:13:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:13:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:13:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:13:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:13:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:13:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:13:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:13:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:13:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:13:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:13:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:13:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:13:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 13, 8, 409600),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33169408,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 12, 7, 933028)}
2018-05-21 07:13:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:13:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:13:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:13:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:13:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:13:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:13:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:13:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:13:11 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:13:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:13:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:13:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:13:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:13:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 13, 12, 629838),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 12, 12, 12741)}
2018-05-21 07:13:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:13:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:13:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:13:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:13:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:13:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:13:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:13:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:13:15 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:13:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:13:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:13:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:13:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:13:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 13, 17, 806024),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33153024,
 'memusage/startup': 32563200,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 12, 17, 321182)}
2018-05-21 07:13:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:13:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:13:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:13:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:13:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:13:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:13:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:13:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:13:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:14:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:14:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:14:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:14:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:14:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:14:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:14:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:14:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 14, 4, 889162),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 13, 4, 305122)}
2018-05-21 07:14:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:14:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:14:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:14:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:14:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:14:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:14:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:14:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:14:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:14:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:14:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:14:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:14:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:14:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:14:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:14:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:14:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:14:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:14:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:14:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 14, 8, 997174),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33161216,
 'memusage/startup': 32542720,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 13, 8, 374226)}
2018-05-21 07:14:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:14:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:14:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:14:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:14:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:14:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:14:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:14:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:14:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:14:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:14:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:14:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:14:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:14:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 14, 12, 788280),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33140736,
 'memusage/startup': 32518144,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 13, 11, 944765)}
2018-05-21 07:14:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:14:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:14:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:14:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:14:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:14:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:14:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:14:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:14:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:14:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:14:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:14:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:14:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:14:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:14:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 14, 16, 363984),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33095680,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 13, 15, 887657)}
2018-05-21 07:14:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:14:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:14:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:14:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:14:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:14:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:14:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:14:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:14:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:15:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:15:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:15:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:15:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:15:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:15:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:15:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:15:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:15:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:15:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:15:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:15:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:15:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 15, 6, 54798),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33656832,
 'memusage/startup': 32911360,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 14, 5, 210157)}
2018-05-21 07:15:06 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:15:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:15:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:15:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:15:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:15:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:15:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:15:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 15, 9, 62177),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33075200,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 14, 8, 580255)}
2018-05-21 07:15:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:15:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:15:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:15:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:15:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:15:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:15:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:15:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:15:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:15:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:15:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 15, 12, 822584),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33964032,
 'memusage/startup': 32890880,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 14, 12, 250384)}
2018-05-21 07:15:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:15:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:15:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:15:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:15:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:15:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:15:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:15:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:15:14 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:15:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:15:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:15:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:15:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:15:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 15, 16, 517344),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33038336,
 'memusage/startup': 32436224,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 14, 16, 32637)}
2018-05-21 07:15:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:15:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:15:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:15:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:15:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:15:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:15:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:15:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:15:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:15:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:15:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:15:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:15:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:15:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:15:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:15:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:15:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:15:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:15:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:16:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:16:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:16:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:16:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:16:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:16:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:16:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:16:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:16:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:16:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:16:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:16:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:16:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 16, 5, 199122),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33542144,
 'memusage/startup': 32862208,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 15, 4, 606425)}
2018-05-21 07:16:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:16:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:16:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:16:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:16:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:16:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:16:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:16:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:16:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:16:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:16:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:10 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:16:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:16:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:16:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 16, 10, 696562),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33095680,
 'memusage/startup': 32489472,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 15, 9, 992986)}
2018-05-21 07:16:10 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:16:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:16:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:16:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:16:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:16:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:16:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:16:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:16:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:16:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:16:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:15 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:16:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:16:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:16:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 16, 15, 406083),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33521664,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 15, 14, 544774)}
2018-05-21 07:16:15 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:16:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:16:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:16:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:16:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:16:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:16:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:16:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 16, 18, 40281),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33034240,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 15, 17, 562916)}
2018-05-21 07:16:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:16:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:16:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:16:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:16:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:16:18 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:16:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:16:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:16:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:16:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:16:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:16:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:16:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:16:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:16:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:16:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:17:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:17:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:17:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:17:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:17:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:17:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:17:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:17:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:17:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:17:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:17:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:17:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:17:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 17, 5, 478474),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33574912,
 'memusage/startup': 32591872,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 16, 4, 877018)}
2018-05-21 07:17:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:17:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:17:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:17:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:17:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:17:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:17:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:17:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:17:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:17:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:17:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:17:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:17:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:17:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 17, 8, 993166),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33574912,
 'memusage/startup': 32960512,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 16, 8, 505124)}
2018-05-21 07:17:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:17:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:17:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:17:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:17:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:17:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:17:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:17:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:17:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:17:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:17:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:17:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:17:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:17:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 17, 14, 495674),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33808384,
 'memusage/startup': 32739328,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 16, 13, 918385)}
2018-05-21 07:17:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:17:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:17:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:17:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:17:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:17:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:17:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:17:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:17:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:17:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:17:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:17:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:17:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:17:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:17:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 17, 19, 208892),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33173504,
 'memusage/startup': 32587776,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 16, 18, 663460)}
2018-05-21 07:17:19 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:17:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:17:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:17:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:17:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:17:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:17:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:17:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:17:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:18:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:18:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:18:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:18:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:18:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:18:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:18:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:18:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:18:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:18:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:18:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:18:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:18:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 18, 5, 155368),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33529856,
 'memusage/startup': 32452608,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 17, 4, 580390)}
2018-05-21 07:18:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:18:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:18:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:18:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:18:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:18:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:18:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:18:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:18:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:18:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:18:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:18:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:18:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:18:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 18, 9, 421636),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33087488,
 'memusage/startup': 32477184,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 17, 8, 845238)}
2018-05-21 07:18:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:18:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:18:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:18:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:18:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:18:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:18:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:18:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:18:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:18:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:18:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:18:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:18:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:18:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 18, 13, 488864),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33517568,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 17, 12, 923089)}
2018-05-21 07:18:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:18:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:18:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:18:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:18:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:18:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:18:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:18:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:18:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:18:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:18:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:18:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:18:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:18:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:18:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 18, 18, 176387),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33361920,
 'memusage/startup': 32714752,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 17, 17, 707079)}
2018-05-21 07:18:18 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:18:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:18:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:18:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:18:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:18:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:18:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:18:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:18:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:19:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:19:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:19:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:19:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:19:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:19:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:19:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:19:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:19:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:19:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:19:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:19:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:19:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 19, 5, 98891),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33525760,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 18, 4, 525074)}
2018-05-21 07:19:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:19:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:19:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:19:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:19:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:19:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:19:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:19:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:19:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:19:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:19:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:19:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:19:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:19:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 19, 8, 869352),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33042432,
 'memusage/startup': 32448512,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 18, 8, 403251)}
2018-05-21 07:19:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:19:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:19:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:19:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:19:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:19:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:19:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:19:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:19:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:19:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:19:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:19:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:19:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:19:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 19, 13, 171547),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33435648,
 'memusage/startup': 32378880,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 18, 12, 591351)}
2018-05-21 07:19:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:19:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:19:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:19:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:19:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:19:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:19:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:19:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:19:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:19:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:19:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:19:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:19:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:19:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:19:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 19, 17, 241103),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33157120,
 'memusage/startup': 32538624,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 18, 16, 773367)}
2018-05-21 07:19:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:19:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:19:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:19:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:19:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:19:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:19:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:19:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:20:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:20:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:20:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:20:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:20:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:20:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:20:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:20:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:20:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:20:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:20:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:20:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 20, 5, 46740),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33460224,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 19, 4, 455943)}
2018-05-21 07:20:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:20:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:20:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:20:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:20:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:20:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:20:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:20:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:20:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:20:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:20:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:20:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:20:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:20:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 20, 8, 987564),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33374208,
 'memusage/startup': 32694272,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 19, 8, 518247)}
2018-05-21 07:20:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:20:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:20:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:20:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:20:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:20:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:20:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:20:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:20:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:20:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:20:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:20:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:20:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:20:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 20, 13, 314728),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33509376,
 'memusage/startup': 32460800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 19, 12, 703984)}
2018-05-21 07:20:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:20:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:20:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:20:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:20:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:20:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:20:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:20:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:20:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:20:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:20:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:20:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:20:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:20:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:20:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 20, 16, 943221),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33574912,
 'memusage/startup': 32964608,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 19, 16, 463515)}
2018-05-21 07:20:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:20:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:20:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:20:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:20:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:20:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:20:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:20:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:20:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:21:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:21:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:21:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:21:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:21:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:21:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:21:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:21:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:21:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:21:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:21:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:21:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:21:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 21, 5, 212295),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33136640,
 'memusage/startup': 32542720,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 20, 4, 618021)}
2018-05-21 07:21:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:21:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:21:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:21:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:21:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:21:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:21:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:21:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:21:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:21:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:21:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:21:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:21:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:21:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 21, 8, 775197),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33091584,
 'memusage/startup': 32419840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 20, 8, 299238)}
2018-05-21 07:21:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:21:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:21:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:21:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:21:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:21:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:21:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:21:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:21:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:21:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:21:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:21:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:21:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:21:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 21, 12, 824249),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33566720,
 'memusage/startup': 32563200,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 20, 12, 251980)}
2018-05-21 07:21:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:21:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:21:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:21:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:21:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:21:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:21:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:21:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:21:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:21:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:21:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:21:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:21:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:21:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:21:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 21, 17, 6656),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33054720,
 'memusage/startup': 32452608,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 20, 16, 529464)}
2018-05-21 07:21:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:21:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:21:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:21:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:21:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:21:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:21:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:21:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:21:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:22:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:22:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:22:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:22:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:22:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:22:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:22:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:22:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:22:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:22:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:22:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:22:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:22:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 22, 4, 893573),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33533952,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 21, 4, 307272)}
2018-05-21 07:22:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:22:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:22:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:22:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:22:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:22:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:22:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:22:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:22:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:22:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:22:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:22:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:22:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:22:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 22, 9, 71256),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33062912,
 'memusage/startup': 32456704,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 21, 8, 596226)}
2018-05-21 07:22:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:22:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:22:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:22:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:22:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:22:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:22:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:22:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:22:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:22:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:22:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:22:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:22:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:22:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 22, 12, 876776),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33984512,
 'memusage/startup': 32931840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 21, 12, 298248)}
2018-05-21 07:22:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:22:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:22:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:22:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:22:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:22:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:22:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:22:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:22:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:22:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:22:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:22:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:22:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:22:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:22:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 22, 16, 506182),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33280000,
 'memusage/startup': 32641024,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 21, 16, 36264)}
2018-05-21 07:22:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:22:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:22:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:22:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:22:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:22:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:22:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:22:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:22:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:23:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:23:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:23:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:23:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:23:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:23:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:23:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:23:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:23:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:23:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:23:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:23:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:23:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 23, 4, 926075),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33783808,
 'memusage/startup': 32686080,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 22, 4, 335389)}
2018-05-21 07:23:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:23:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:23:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:23:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:23:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:23:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:23:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:23:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:23:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:23:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:23:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:23:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:23:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:23:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 23, 8, 663311),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 32993280,
 'memusage/startup': 32419840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 22, 8, 191730)}
2018-05-21 07:23:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:23:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:23:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:23:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:23:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:23:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:23:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:23:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:23:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:23:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:23:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:23:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:23:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:23:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 23, 12, 907187),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33439744,
 'memusage/startup': 32485376,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 22, 12, 316393)}
2018-05-21 07:23:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:23:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:23:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:23:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:23:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:23:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:23:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:23:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:23:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:23:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:23:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:23:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:23:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:23:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:23:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 23, 16, 586194),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33124352,
 'memusage/startup': 32514048,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 22, 16, 105787)}
2018-05-21 07:23:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:23:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:23:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:23:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:23:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:23:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:23:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:23:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:23:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:24:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:24:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:24:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:24:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:24:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:24:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:24:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:24:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:24:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:24:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:24:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:24:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:24:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 24, 5, 488684),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33816576,
 'memusage/startup': 32763904,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 23, 4, 799983)}
2018-05-21 07:24:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:24:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:24:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:24:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:24:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:24:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:24:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:24:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:24:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:24:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:24:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:24:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:24:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:24:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 24, 9, 29025),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33394688,
 'memusage/startup': 32620544,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 23, 8, 507777)}
2018-05-21 07:24:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:24:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:24:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:24:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:24:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:24:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:24:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:24:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:24:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:24:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:24:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:24:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:24:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:24:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 24, 13, 101311),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33443840,
 'memusage/startup': 32489472,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 23, 12, 394878)}
2018-05-21 07:24:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:24:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:24:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:24:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:24:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:24:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:24:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:24:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:24:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:24:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:24:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:24:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:24:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:24:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:24:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 24, 16, 650310),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33529856,
 'memusage/startup': 32915456,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 23, 16, 169156)}
2018-05-21 07:24:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:24:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:24:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:24:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:24:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:24:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:24:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:24:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:24:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:25:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:25:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:25:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:25:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:25:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:25:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:25:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:25:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:25:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:25:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:25:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:25:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:25:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 25, 5, 454527),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33714176,
 'memusage/startup': 32628736,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 24, 4, 860675)}
2018-05-21 07:25:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:25:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:25:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:25:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:25:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:25:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:25:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:25:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:25:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:25:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:25:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:25:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:25:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:25:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 25, 9, 197611),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33316864,
 'memusage/startup': 32706560,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 24, 8, 726393)}
2018-05-21 07:25:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:25:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:25:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:25:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:25:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:25:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:25:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:25:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:25:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 25, 12, 893329),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33546240,
 'memusage/startup': 32563200,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 24, 12, 293571)}
2018-05-21 07:25:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:25:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:25:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:25:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:25:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:25:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:25:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:25:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:25:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:25:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:25:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:25:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:25:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:25:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:25:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:25:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:25:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:25:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:25:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:25:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 25, 16, 890787),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33071104,
 'memusage/startup': 32473088,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 24, 16, 400621)}
2018-05-21 07:25:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:25:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:25:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:25:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:25:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:25:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:25:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:25:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:25:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:26:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:26:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:26:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:26:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:26:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:26:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:26:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:26:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:26:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:26:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:26:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:26:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:26:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 26, 5, 680851),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33406976,
 'memusage/startup': 32677888,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 25, 5, 90258)}
2018-05-21 07:26:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:26:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:26:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:26:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:26:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:26:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:26:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:26:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:26:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:26:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:26:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:26:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:26:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:26:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 26, 9, 384951),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33366016,
 'memusage/startup': 32755712,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 25, 8, 896745)}
2018-05-21 07:26:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:26:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:26:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:26:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:26:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:26:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:26:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:26:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:26:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:26:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:26:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:26:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:26:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:26:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 26, 14, 246835),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33681408,
 'memusage/startup': 32645120,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 25, 13, 434828)}
2018-05-21 07:26:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:26:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:26:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:26:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:26:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:26:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:26:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:26:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:26:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:26:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:26:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:26:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:26:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:26:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:26:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 26, 17, 441704),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33656832,
 'memusage/startup': 32915456,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 25, 16, 832948)}
2018-05-21 07:26:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:26:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:26:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:26:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:26:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:26:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:26:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:26:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:26:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:27:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:27:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:27:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:27:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:27:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:27:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:27:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:27:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:27:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:27:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:27:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:27:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 27, 4, 996991),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33492992,
 'memusage/startup': 32428032,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 26, 4, 400545)}
2018-05-21 07:27:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:27:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:27:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:27:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:27:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:27:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:27:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:27:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:27:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:27:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:27:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:27:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:27:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:27:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:27:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 27, 9, 373731),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33112064,
 'memusage/startup': 32444416,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 26, 8, 871009)}
2018-05-21 07:27:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:27:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:27:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:27:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:27:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:27:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:27:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:27:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:27:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:27:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:27:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:27:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:27:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 27, 13, 234303),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 26, 12, 625121)}
2018-05-21 07:27:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:27:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:27:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:27:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:27:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:27:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:27:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:27:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:27:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:27:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:27:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:27:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:27:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:27:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:27:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:27:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 27, 17, 997835),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 32968704,
 'memusage/startup': 32382976,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 26, 17, 403556)}
2018-05-21 07:27:18 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:27:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:27:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:27:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:27:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:27:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:27:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:27:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:27:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:28:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:28:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:28:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:28:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:28:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:28:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:28:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:28:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:28:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:28:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:28:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:28:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:28:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 28, 5, 834223),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33787904,
 'memusage/startup': 32698368,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 27, 5, 19554)}
2018-05-21 07:28:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:28:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:28:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:28:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:28:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:28:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:28:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:28:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:28:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:28:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:28:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:28:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:28:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:28:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 28, 9, 207544),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33517568,
 'memusage/startup': 32780288,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 27, 8, 727101)}
2018-05-21 07:28:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:28:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:28:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:28:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:28:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:28:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:28:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:28:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:28:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:28:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:28:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:28:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:28:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:28:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 28, 14, 36820),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33538048,
 'memusage/startup': 32792576,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 27, 13, 248591)}
2018-05-21 07:28:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:28:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:28:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:28:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:28:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:28:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:28:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:28:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:28:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 28, 17, 201588),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 32948224,
 'memusage/startup': 32358400,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 27, 16, 730597)}
2018-05-21 07:28:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:28:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:28:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:28:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:28:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:28:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:28:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:28:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:28:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:28:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:28:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:28:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:28:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:28:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:29:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:29:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:29:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:29:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:29:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:29:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:29:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:29:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:29:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:29:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:29:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:29:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:29:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 29, 4, 865236),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33030144,
 'memusage/startup': 32428032,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 28, 4, 287041)}
2018-05-21 07:29:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:29:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:29:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:29:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:29:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:29:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:29:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:29:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:29:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:29:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:29:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:29:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:29:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:29:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 29, 9, 520968),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33275904,
 'memusage/startup': 32636928,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 28, 9, 38222)}
2018-05-21 07:29:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:29:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:29:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:29:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:29:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:29:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:29:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:29:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 29, 13, 118704),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 34009088,
 'memusage/startup': 32931840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 28, 12, 514304)}
2018-05-21 07:29:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:29:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:29:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:29:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:29:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:29:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:29:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:29:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:29:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:29:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:29:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:29:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:29:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:29:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:29:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:29:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:29:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:29:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:29:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:29:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:29:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 29, 17, 913787),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33054720,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 28, 17, 313182)}
2018-05-21 07:29:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:29:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:29:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:29:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:29:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:29:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:29:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:29:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:29:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:30:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:30:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:30:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:30:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 30, 5, 410595),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 29, 4, 720988)}
2018-05-21 07:30:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:30:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:30:06 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:30:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:30:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:30:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:30:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:30:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:30:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:30:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:30:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:30:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:30:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:30:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 30, 8, 894200),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33181696,
 'memusage/startup': 32591872,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 29, 8, 415933)}
2018-05-21 07:30:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:30:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:30:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:30:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:30:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:30:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:30:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:30:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:30:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:30:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:30:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:30:14 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:30:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:30:14 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:30:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:30:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:30:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 30, 14, 707159),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33652736,
 'memusage/startup': 32583680,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 29, 13, 878621)}
2018-05-21 07:30:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:30:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:30:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:30:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:30:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:30:15 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:30:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:30:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:30:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:30:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:30:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 30, 17, 536577),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33165312,
 'memusage/startup': 32595968,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 29, 17, 59954)}
2018-05-21 07:30:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:30:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:30:18 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:30:18 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:30:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:30:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:30:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:30:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:30:18 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:30:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:30:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:30:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:30:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:30:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:30:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:30:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:30:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:30:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:31:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:31:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:31:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:31:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:31:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:31:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:31:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:31:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:31:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6028
2018-05-21 07:31:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:31:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:31:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:31:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 31, 9, 900545),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33751040,
 'memusage/startup': 32739328,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 30, 8, 699246)}
2018-05-21 07:31:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:31:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:31:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:31:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:31:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:31:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:31:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:31:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:31:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:31:14 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:31:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:31:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:31:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:31:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 31, 14, 201495),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33226752,
 'memusage/startup': 32612352,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 30, 13, 558148)}
2018-05-21 07:31:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:31:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:31:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:31:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:31:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 31, 16, 307528),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33513472,
 'memusage/startup': 32460800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 30, 15, 492948)}
2018-05-21 07:31:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:31:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:31:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:31:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:31:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:31:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:31:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:31:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:31:18 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:31:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:31:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:31:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:31:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:31:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 31, 19, 285187),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33042432,
 'memusage/startup': 32440320,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 30, 18, 737098)}
2018-05-21 07:31:19 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:31:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:31:20 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:31:20 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:31:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:31:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:31:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:31:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:31:21 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:31:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:31:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:31:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:31:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:31:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:31:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:31:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:31:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:31:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:32:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:32:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:32:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:32:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:32:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:32:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:32:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:32:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:32:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:32:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:32:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:32:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:32:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:32:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 32, 5, 716157),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33619968,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 31, 5, 126402)}
2018-05-21 07:32:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:32:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:32:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:32:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:32:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:32:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:32:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:32:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:32:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:32:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:32:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:32:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:32:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:32:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 32, 14, 732040),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33607680,
 'memusage/startup': 32919552,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 31, 14, 46990)}
2018-05-21 07:32:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:32:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:32:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:32:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:32:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:32:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:32:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:32:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:32:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:32:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:32:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:32:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:32:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:32:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 32, 19, 748526),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33619968,
 'memusage/startup': 32595968,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 31, 18, 874036)}
2018-05-21 07:32:19 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:32:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:21 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:32:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:32:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:32:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 32, 21, 823602),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33075200,
 'memusage/startup': 32473088,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 31, 21, 351322)}
2018-05-21 07:32:21 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:32:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:32:22 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:32:22 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:32:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:32:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:32:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:32:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:32:23 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:32:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:32:23 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:32:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:32:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:32:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:32:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:32:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:32:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:33:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:33:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:33:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:33:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:33:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:33:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:33:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:33:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:33:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:33:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:33:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:33:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:33:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:33:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 33, 5, 433943),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33689600,
 'memusage/startup': 32669696,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 32, 4, 850632)}
2018-05-21 07:33:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:33:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:33:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:33:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:33:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:33:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:33:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:33:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:33:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:33:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:33:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:33:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:33:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:33:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 33, 9, 252479),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33394688,
 'memusage/startup': 32681984,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 32, 8, 791193)}
2018-05-21 07:33:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:33:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:33:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:33:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:33:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:33:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:33:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:33:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:33:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:33:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:33:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:33:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:33:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:33:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 33, 18, 640561),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33476608,
 'memusage/startup': 32460800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 32, 17, 985465)}
2018-05-21 07:33:18 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:33:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:33:21 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:33:21 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:33:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:33:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:33:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:33:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:33:21 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:33:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:33:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:33:23 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:33:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:33:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:33:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 33, 23, 546999),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33030144,
 'memusage/startup': 32444416,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 32, 23, 54105)}
2018-05-21 07:33:23 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:33:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:33:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:33:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:33:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:33:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:33:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:33:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:34:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:34:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:34:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:34:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:34:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:34:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:34:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:34:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:34:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:34:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:34:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:34:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:34:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:34:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 34, 4, 924698),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33755136,
 'memusage/startup': 32702464,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 33, 4, 336696)}
2018-05-21 07:34:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:34:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:34:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:34:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:34:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:34:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:34:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:34:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:34:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:34:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:34:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:34:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:34:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:34:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 34, 9, 354100),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33030144,
 'memusage/startup': 32428032,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 33, 8, 872327)}
2018-05-21 07:34:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:34:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:34:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:34:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:34:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:34:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:34:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:34:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:34:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:34:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:34:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:34:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:34:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:34:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 34, 13, 596901),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33443840,
 'memusage/startup': 32468992,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 33, 13, 20722)}
2018-05-21 07:34:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:34:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:34:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:34:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:34:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:34:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:34:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:34:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:34:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:34:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:34:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:34:22 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:34:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:34:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:34:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 34, 22, 324506),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33435648,
 'memusage/startup': 32755712,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 33, 21, 850810)}
2018-05-21 07:34:22 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:34:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:34:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:34:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:34:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:34:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:34:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:34:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:34:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:35:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:35:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:35:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:35:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:35:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:35:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:35:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:35:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:35:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:35:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:35:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:35:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:35:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 35, 5, 621247),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33619968,
 'memusage/startup': 32579584,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 34, 4, 876971)}
2018-05-21 07:35:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:35:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:35:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:35:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:35:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:35:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:35:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:35:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:35:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 35, 8, 922491),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33095680,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 34, 8, 373966)}
2018-05-21 07:35:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:35:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:35:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:35:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:35:09 [scrapy.core.engine] INFO: Spider opened

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:35:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:35:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:35:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:35:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:35:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:35:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:35:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:35:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:35:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:35:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:35:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:35:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:35:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:35:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 35, 13, 172350),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 34000896,
 'memusage/startup': 32931840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 34, 12, 594617)}
2018-05-21 07:35:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:35:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:35:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:35:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:35:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:35:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:35:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:35:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:35:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:35:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:35:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:35:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:35:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:35:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 35, 17, 298864),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33026048,
 'memusage/startup': 32485376,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 34, 16, 827862)}
2018-05-21 07:35:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:35:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:35:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:35:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:35:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:35:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:35:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:35:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:36:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:36:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:36:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:36:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:36:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:36:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:36:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:36:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:36:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:36:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:36:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:36:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:36:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 36, 5, 227348),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33660928,
 'memusage/startup': 32620544,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 35, 4, 662428)}
2018-05-21 07:36:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:36:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:36:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:36:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:36:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:36:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:36:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:36:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:36:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:36:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:36:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:36:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:36:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:36:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 36, 9, 932021),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33128448,
 'memusage/startup': 32518144,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 35, 9, 286017)}
2018-05-21 07:36:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:36:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:36:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:36:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:36:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:36:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:36:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:36:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:36:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:36:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:36:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:36:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:36:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:36:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 36, 13, 412363),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33660928,
 'memusage/startup': 32612352,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 35, 12, 821782)}
2018-05-21 07:36:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:36:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:36:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:36:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:36:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:36:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:36:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:36:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:36:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:36:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:36:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:36:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:36:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:36:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:36:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 36, 16, 862134),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33488896,
 'memusage/startup': 32878592,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 35, 16, 377849)}
2018-05-21 07:36:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:36:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:36:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:36:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:36:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:36:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:36:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:36:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:37:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:37:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:37:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:37:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:37:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:37:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:37:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:37:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:37:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:37:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:37:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:37:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:37:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 37, 5, 133095),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33517568,
 'memusage/startup': 32452608,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 36, 4, 529122)}
2018-05-21 07:37:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:37:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:37:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:37:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:37:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:37:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:37:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:37:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:37:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:37:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:37:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:37:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:37:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:37:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 37, 8, 942178),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33341440,
 'memusage/startup': 32636928,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 36, 8, 460029)}
2018-05-21 07:37:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:37:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:37:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:37:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:37:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:37:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:37:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:37:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:37:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:37:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:37:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:37:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:37:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:37:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 37, 13, 693815),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33722368,
 'memusage/startup': 32727040,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 36, 13, 92789)}
2018-05-21 07:37:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:37:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:37:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:37:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:37:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:37:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:37:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:37:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:37:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:37:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:37:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:37:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:37:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:37:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:37:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 37, 17, 121836),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33091584,
 'memusage/startup': 32489472,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 36, 16, 640515)}
2018-05-21 07:37:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:37:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:37:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:37:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:37:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:37:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:37:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:37:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:38:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:38:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:38:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:38:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:38:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:38:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:38:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:38:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:38:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:38:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:38:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:38:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:38:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 38, 4, 834994),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33648640,
 'memusage/startup': 32509952,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 37, 4, 249805)}
2018-05-21 07:38:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:38:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:38:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:38:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:38:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:38:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:38:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:38:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:38:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:38:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:38:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:38:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:38:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:38:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 38, 9, 49367),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33558528,
 'memusage/startup': 32948224,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 37, 8, 563548)}
2018-05-21 07:38:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:38:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:38:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:38:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:38:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:38:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:38:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:38:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:38:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:38:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:38:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:38:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:38:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:38:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 38, 13, 324293),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33492992,
 'memusage/startup': 32444416,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 37, 12, 748338)}
2018-05-21 07:38:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:38:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:38:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:38:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:38:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:38:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:38:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:38:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:38:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:38:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:38:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:38:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:38:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:38:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:38:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 38, 17, 399415),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33271808,
 'memusage/startup': 32632832,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 37, 16, 915868)}
2018-05-21 07:38:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:38:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:38:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:38:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:38:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:38:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:38:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:38:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:39:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:39:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:39:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:39:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:39:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:39:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:39:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:39:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:39:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:39:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:39:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:39:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:39:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 39, 5, 73874),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33447936,
 'memusage/startup': 32378880,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 38, 4, 487029)}
2018-05-21 07:39:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:39:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:39:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:39:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:39:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:39:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:39:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:39:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:39:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:39:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:39:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:39:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:39:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:39:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 39, 8, 578350),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33284096,
 'memusage/startup': 32538624,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 38, 8, 31104)}
2018-05-21 07:39:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:39:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:39:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:39:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:39:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:39:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:39:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:39:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:39:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:39:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:39:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:39:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:39:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:39:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 39, 12, 871935),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33419264,
 'memusage/startup': 32419840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 38, 12, 241298)}
2018-05-21 07:39:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:39:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:39:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:39:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:39:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:39:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:39:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:39:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:39:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:39:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:39:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:39:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:39:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:39:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:39:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 39, 16, 983846),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33153024,
 'memusage/startup': 32571392,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 38, 16, 519005)}
2018-05-21 07:39:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:39:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:39:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:39:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:39:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:39:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:39:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:39:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:40:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:40:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:40:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:40:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:40:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:40:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:40:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:40:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:40:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:40:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:40:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:40:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:40:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 40, 5, 365023),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33587200,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 39, 4, 776593)}
2018-05-21 07:40:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:40:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:40:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:40:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:40:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:40:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:40:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:40:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:40:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:40:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:40:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:40:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:40:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:40:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 40, 9, 157507),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33091584,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 39, 8, 539632)}
2018-05-21 07:40:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:40:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:40:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:40:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:40:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:40:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:40:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:40:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:40:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:40:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:40:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:40:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:40:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:40:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 40, 13, 194241),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33386496,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 39, 12, 412873)}
2018-05-21 07:40:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:40:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:40:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:40:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:40:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:40:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:40:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:40:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:40:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:40:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:40:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:40:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:40:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:40:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:40:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 40, 16, 590405),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33374208,
 'memusage/startup': 32632832,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 39, 16, 123054)}
2018-05-21 07:40:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:40:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:40:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:40:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:40:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:40:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:40:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:40:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:40:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:41:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:41:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:41:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:41:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:41:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:41:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:41:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:41:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 41, 4, 914895),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33566720,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 40, 4, 326351)}
2018-05-21 07:41:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:41:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:41:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:41:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:41:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:41:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:41:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:41:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:41:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:41:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:41:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:41:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:41:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:41:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:41:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:41:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:41:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:41:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:41:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 41, 9, 71383),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33304576,
 'memusage/startup': 32665600,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 40, 8, 610763)}
2018-05-21 07:41:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:41:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:41:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:41:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:41:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:41:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:41:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:41:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:41:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:41:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:41:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:41:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:41:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:41:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 41, 12, 950447),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33443840,
 'memusage/startup': 32436224,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 40, 12, 367190)}
2018-05-21 07:41:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:41:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:41:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:41:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:41:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:41:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:41:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:41:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:41:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:41:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:41:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:41:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:41:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:41:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:41:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 41, 16, 979313),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33370112,
 'memusage/startup': 32694272,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 40, 16, 455823)}
2018-05-21 07:41:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:41:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:41:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:41:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:41:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:41:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:41:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:41:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:41:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:42:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:42:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:42:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:42:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:42:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:42:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:42:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:42:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:42:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:42:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:42:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:42:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:42:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 42, 5, 834363),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33968128,
 'memusage/startup': 32894976,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 41, 5, 18178)}
2018-05-21 07:42:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:42:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:42:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:42:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:42:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:42:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:42:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:42:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:42:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:42:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:42:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:42:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:42:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:42:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 42, 9, 216580),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33071104,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 41, 8, 714062)}
2018-05-21 07:42:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:42:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:42:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:42:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:42:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:42:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:42:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:42:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:42:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:42:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:42:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:42:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:42:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:42:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 42, 13, 136352),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33759232,
 'memusage/startup': 32698368,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 41, 12, 556407)}
2018-05-21 07:42:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:42:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:42:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:42:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:42:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:42:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:42:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:42:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:42:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:42:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:42:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:42:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:42:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:42:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:42:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 42, 16, 674092),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33234944,
 'memusage/startup': 32604160,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 41, 16, 193198)}
2018-05-21 07:42:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:42:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:42:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:42:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:42:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:42:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:42:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:42:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:43:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:43:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:43:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:43:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:43:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:43:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:43:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:43:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:43:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:43:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 43, 4, 927584),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33476608,
 'memusage/startup': 32448512,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 42, 4, 339639)}
2018-05-21 07:43:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:43:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:43:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:43:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:43:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:43:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:43:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:43:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:43:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:43:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:43:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:43:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:43:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:43:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:43:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:43:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:43:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 43, 9, 640434),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33050624,
 'memusage/startup': 32444416,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 42, 9, 97289)}
2018-05-21 07:43:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:43:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:43:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:43:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:43:13 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:43:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:43:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:43:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 43, 13, 221413),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33665024,
 'memusage/startup': 32612352,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 42, 12, 610552)}
2018-05-21 07:43:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:43:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:43:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:43:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:43:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:43:14 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:43:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:43:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:43:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:43:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:43:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:43:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:43:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:43:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 43, 16, 904877),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33079296,
 'memusage/startup': 32489472,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 42, 16, 405912)}
2018-05-21 07:43:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:43:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:43:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:43:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:43:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:43:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:43:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:43:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:43:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:43:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:43:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:43:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:43:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:43:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:43:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:43:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:44:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:44:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:44:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:44:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:44:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:44:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:44:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:44:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:44:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:44:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:44:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:44:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:44:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 44, 5, 785923),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33464320,
 'memusage/startup': 32448512,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 43, 4, 985995)}
2018-05-21 07:44:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:44:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:44:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:44:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:44:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:44:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:44:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:44:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:44:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:44:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:44:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:44:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:44:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:44:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 44, 9, 231680),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33370112,
 'memusage/startup': 32751616,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 43, 8, 748464)}
2018-05-21 07:44:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:44:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:44:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:44:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:44:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:44:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:44:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:44:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:44:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:44:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:44:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:44:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:44:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:44:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 44, 15, 159674),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33677312,
 'memusage/startup': 32645120,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 43, 14, 329608)}
2018-05-21 07:44:15 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:44:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:44:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:44:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:44:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:44:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:44:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:44:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 44, 18, 13055),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33488896,
 'memusage/startup': 32882688,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 43, 17, 518376)}
2018-05-21 07:44:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:44:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:44:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:44:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:44:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:44:18 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:44:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:44:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:44:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:44:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:44:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:44:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:44:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:44:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:45:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:45:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:45:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:45:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:45:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:45:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:45:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:45:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:45:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:45:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:45:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:45:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:45:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 45, 4, 904473),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33050624,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 44, 4, 314375)}
2018-05-21 07:45:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:45:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:45:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:45:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:45:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:45:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:45:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:45:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:45:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:45:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:45:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:45:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:45:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:45:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 45, 9, 391939),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33353728,
 'memusage/startup': 32743424,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 44, 8, 920693)}
2018-05-21 07:45:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:45:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:45:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:45:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:45:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:45:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:45:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:45:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:45:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 45, 13, 76873),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33570816,
 'memusage/startup': 32579584,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 44, 12, 479134)}
2018-05-21 07:45:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:45:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:45:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:45:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:45:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:45:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:45:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:45:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:45:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:45:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:45:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:45:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:45:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:45:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:45:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:45:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:45:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:45:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:45:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:45:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 45, 19, 42398),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33128448,
 'memusage/startup': 32522240,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 44, 18, 571155)}
2018-05-21 07:45:19 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:45:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:45:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:45:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:45:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:45:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:45:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:45:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:45:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:46:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:46:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:46:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:46:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:46:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:46:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:46:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:46:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:46:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:46:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:46:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:46:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 46, 5, 98770),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33763328,
 'memusage/startup': 32706560,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 45, 4, 511833)}
2018-05-21 07:46:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:46:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:46:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:46:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:46:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:46:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:46:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:46:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:46:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:46:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:46:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:46:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:46:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:46:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 46, 8, 783224),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 32964608,
 'memusage/startup': 32374784,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 45, 8, 283169)}
2018-05-21 07:46:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:46:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:46:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:46:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:46:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:46:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:46:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:46:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:46:11 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:46:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:46:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:46:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:46:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:46:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 46, 14, 46032),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33611776,
 'memusage/startup': 32567296,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 45, 13, 189470)}
2018-05-21 07:46:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:46:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:46:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:46:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:46:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:46:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:46:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:46:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:46:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:46:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 46, 17, 198654),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 32972800,
 'memusage/startup': 32391168,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 45, 16, 728526)}
2018-05-21 07:46:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:46:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:46:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:46:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:46:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:46:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:46:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:46:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:46:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:46:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:46:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:46:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:46:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:46:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:47:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:47:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:47:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:47:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:47:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:47:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:47:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:47:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:47:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:47:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:47:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:47:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:47:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 47, 5, 4861),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33615872,
 'memusage/startup': 32567296,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 46, 4, 414333)}
2018-05-21 07:47:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:47:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:47:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:47:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:47:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:47:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:47:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:47:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:47:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:47:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:47:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:47:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:47:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:47:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 47, 8, 770391),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33361920,
 'memusage/startup': 32677888,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 46, 8, 297601)}
2018-05-21 07:47:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:47:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:47:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:47:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:47:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:47:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:47:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:47:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:47:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:47:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:47:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:47:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:47:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:47:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 47, 12, 662989),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33677312,
 'memusage/startup': 32665600,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 46, 12, 46966)}
2018-05-21 07:47:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:47:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:47:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:47:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:47:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:47:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:47:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:47:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:47:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:47:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:47:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:47:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:47:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:47:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:47:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 47, 17, 981502),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32940032,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 46, 17, 309785)}
2018-05-21 07:47:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:47:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:47:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:47:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:47:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:47:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:47:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:47:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:48:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:48:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:48:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:48:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:48:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:48:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:48:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:48:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:48:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:48:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:48:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:48:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:48:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 48, 5, 471381),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33464320,
 'memusage/startup': 32489472,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 47, 4, 826489)}
2018-05-21 07:48:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:48:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:48:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:48:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:48:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:48:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:48:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:48:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:48:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:48:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:48:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:48:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:48:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:48:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 48, 9, 54435),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33054720,
 'memusage/startup': 32509952,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 47, 8, 562028)}
2018-05-21 07:48:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:48:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:48:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:48:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:48:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:48:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:48:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:48:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:48:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:48:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:48:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:48:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:48:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:48:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 48, 13, 569684),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33968128,
 'memusage/startup': 32915456,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 47, 12, 536017)}
2018-05-21 07:48:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:48:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:48:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:48:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:48:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:48:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:48:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:48:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:48:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:48:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:48:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:48:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:48:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:48:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 48, 16, 880991),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33304576,
 'memusage/startup': 32694272,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 47, 16, 389633)}
2018-05-21 07:48:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:48:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:48:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:48:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:48:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:48:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:48:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:48:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:48:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:49:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:49:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:49:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:49:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:49:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:49:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:49:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:49:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:49:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:49:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:49:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:49:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:49:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 49, 4, 981496),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33464320,
 'memusage/startup': 32501760,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 48, 4, 384774)}
2018-05-21 07:49:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:49:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:49:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:49:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:49:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:49:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:49:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:49:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:49:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:49:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:49:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:49:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:49:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:49:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 49, 9, 195432),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33284096,
 'memusage/startup': 32571392,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 48, 8, 707925)}
2018-05-21 07:49:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:49:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:49:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:49:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:49:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:49:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:49:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:49:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:49:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 49, 12, 945550),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33624064,
 'memusage/startup': 32608256,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 48, 12, 354676)}
2018-05-21 07:49:12 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:49:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:49:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:49:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:49:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:49:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:49:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:49:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:49:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:49:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:49:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:49:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:49:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:49:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:49:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:49:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:49:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:49:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:49:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:49:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 49, 17, 498526),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33091584,
 'memusage/startup': 32518144,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 48, 16, 863628)}
2018-05-21 07:49:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:49:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:49:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:49:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:49:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:49:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:49:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:49:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:49:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:50:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:50:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:50:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:50:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:50:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:50:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:50:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:50:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:50:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:50:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:50:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:50:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:50:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 50, 5, 46533),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33087488,
 'memusage/startup': 32460800,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 49, 4, 448746)}
2018-05-21 07:50:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:50:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:50:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:50:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:50:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:50:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:50:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:50:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:50:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:50:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:50:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:50:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:50:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:50:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 50, 8, 975418),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33181696,
 'memusage/startup': 32595968,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 49, 8, 507366)}
2018-05-21 07:50:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:50:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:50:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:50:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:50:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:50:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:50:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:50:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:50:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:50:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:50:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:50:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:50:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:50:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 50, 14, 411229),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33988608,
 'memusage/startup': 32931840,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 49, 13, 538116)}
2018-05-21 07:50:14 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:50:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:50:17 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:50:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:50:17 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:50:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:50:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:50:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:50:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 50, 17, 334071),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33034240,
 'memusage/startup': 32440320,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 49, 16, 845876)}
2018-05-21 07:50:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:50:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:50:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:50:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:50:17 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:50:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:50:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:50:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:50:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:50:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:50:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:50:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:50:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:50:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:50:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:51:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:51:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:51:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:51:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:51:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:51:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:51:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:51:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:51:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:51:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:51:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:51:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:51:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 51, 5, 435775),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33480704,
 'memusage/startup': 32411648,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 50, 4, 842693)}
2018-05-21 07:51:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:51:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:51:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:51:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:51:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:51:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:51:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:51:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 51, 8, 791065),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33103872,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 50, 8, 315078)}
2018-05-21 07:51:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:51:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:51:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:51:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:51:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:51:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:51:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:51:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:51:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:51:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:51:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:51:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:51:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 51, 12, 856310),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33538048,
 'memusage/startup': 32456704,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 50, 12, 259929)}
2018-05-21 07:51:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:51:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:51:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:51:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:51:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:51:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:51:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:51:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:51:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:51:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:51:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:51:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:51:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:51:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:51:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:51:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:51:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:51:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 51, 18, 338875),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33296384,
 'memusage/startup': 32657408,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 50, 17, 873172)}
2018-05-21 07:51:18 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:51:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:51:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:51:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:51:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:51:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:52:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:52:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:52:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:52:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:52:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:52:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:52:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:52:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:52:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:52:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:52:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:52:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:52:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 52, 5, 483814),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 34000896,
 'memusage/startup': 32952320,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 51, 4, 907580)}
2018-05-21 07:52:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:52:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:52:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:52:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:52:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:52:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:52:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:52:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:52:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:52:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:52:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:52:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:52:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:52:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 52, 9, 625564),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33550336,
 'memusage/startup': 32940032,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 51, 8, 974389)}
2018-05-21 07:52:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:52:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:52:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:52:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:52:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:52:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:52:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:52:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:52:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:52:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:52:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:52:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:52:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 52, 13, 897935),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33640448,
 'memusage/startup': 32587776,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 51, 13, 10522)}
2018-05-21 07:52:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:52:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:52:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:52:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:52:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:52:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:52:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:52:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:52:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 52, 17, 3985),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33501184,
 'memusage/startup': 32768000,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 51, 16, 531941)}
2018-05-21 07:52:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:52:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:52:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:52:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:52:17 [scrapy.core.engine] INFO: Spider opened

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:52:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:52:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:52:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:52:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:52:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:52:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:52:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:52:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:52:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:52:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:53:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:53:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:53:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:53:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:53:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:53:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:53:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:53:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:53:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:53:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:53:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:53:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:53:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 53, 5, 282802),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33640448,
 'memusage/startup': 32514048,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 52, 4, 698216)}
2018-05-21 07:53:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:53:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:53:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:53:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:53:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:53:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:53:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:53:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:53:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:53:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:53:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:53:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:53:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:53:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 53, 9, 221003),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33230848,
 'memusage/startup': 32493568,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 52, 8, 668521)}
2018-05-21 07:53:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:53:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:53:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:53:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:53:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:53:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:53:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:53:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:53:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:53:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:53:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:53:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:53:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:53:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 53, 13, 399681),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33390592,
 'memusage/startup': 32387072,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 52, 12, 807689)}
2018-05-21 07:53:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:53:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:53:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:53:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:53:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:53:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:53:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:53:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:53:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:53:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:53:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:53:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:53:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:53:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:53:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 53, 17, 834132),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33357824,
 'memusage/startup': 32739328,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 52, 17, 356839)}
2018-05-21 07:53:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:53:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:53:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:53:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:53:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:53:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:53:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:53:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:53:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:54:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:54:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:54:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:54:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:54:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:54:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:54:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:54:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:54:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:54:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:54:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:54:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 54, 5, 114148),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33562624,
 'memusage/startup': 32497664,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 53, 4, 537666)}
2018-05-21 07:54:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:54:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:54:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:54:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:54:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:54:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:54:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:54:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:54:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:54:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:54:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:54:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:54:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:54:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 54, 9, 176909),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33312768,
 'memusage/startup': 32665600,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 53, 8, 698150)}
2018-05-21 07:54:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:54:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:54:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:54:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:54:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:54:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:54:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:54:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:54:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:54:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:54:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:13 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:54:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:54:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:54:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 54, 13, 585287),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33755136,
 'memusage/startup': 32690176,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 53, 12, 989671)}
2018-05-21 07:54:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:54:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:54:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:54:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:54:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:54:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:54:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:54:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:54:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:54:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:54:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:54:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:54:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:54:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:54:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 54, 17, 114683),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33071104,
 'memusage/startup': 32477184,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 53, 16, 630686)}
2018-05-21 07:54:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:54:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:54:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:54:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:54:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:54:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:54:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:54:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:54:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:55:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:55:03 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:55:03 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:55:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:55:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:55:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:55:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:55:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:55:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:55:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:55:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 55, 4, 731871),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33538048,
 'memusage/startup': 32481280,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 54, 4, 152276)}
2018-05-21 07:55:04 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:55:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:55:07 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:55:07 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:55:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:55:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:55:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:55:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:55:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:55:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:55:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:55:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:55:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:55:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 55, 8, 823125),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33021952,
 'memusage/startup': 32432128,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 54, 8, 290004)}
2018-05-21 07:55:08 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:55:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:55:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:55:11 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:55:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:55:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:55:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:55:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:55:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:55:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:55:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:55:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:55:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:55:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 55, 12, 997756),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33517568,
 'memusage/startup': 32546816,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 54, 12, 402951)}
2018-05-21 07:55:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:55:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:55:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:55:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:55:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:55:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:55:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:55:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:55:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:55:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:55:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:55:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:55:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:55:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:55:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 55, 17, 210237),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33034240,
 'memusage/startup': 32436224,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 54, 16, 743218)}
2018-05-21 07:55:17 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:55:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:55:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:55:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:55:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:55:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:55:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:55:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:55:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:56:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:56:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:56:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:56:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:56:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:56:04 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:56:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:56:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:56:04 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:56:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:04 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:56:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:56:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:56:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 56, 5, 69848),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33087488,
 'memusage/startup': 32473088,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 55, 4, 476043)}
2018-05-21 07:56:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:56:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:56:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:56:08 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:56:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:56:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:56:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 56, 8, 741169),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33140736,
 'memusage/startup': 32522240,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 55, 8, 249255)}
2018-05-21 07:56:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:56:08 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:56:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:56:11 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:56:12 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:56:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:56:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:56:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:56:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:56:12 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:56:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:56:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:56:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:56:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:56:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 56, 13, 213288),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33533952,
 'memusage/startup': 32546816,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 55, 12, 517659)}
2018-05-21 07:56:13 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:56:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:56:15 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:56:15 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:56:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:56:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:56:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:56:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:56:16 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:56:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:56:16 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-05-21 07:56:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:56:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:56:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:56:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 56, 16, 744411),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33304576,
 'memusage/startup': 32669696,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 55, 16, 251536)}
2018-05-21 07:56:16 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:56:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:56:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:56:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:56:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:56:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:56:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:56:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:56:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:57:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:57:04 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:57:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:57:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:57:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:57:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:57:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:57:05 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:57:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-05-21 07:57:05 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:57:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://brasilianismo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:57:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:57:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 57, 5, 633901),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33583104,
 'memusage/startup': 32571392,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 56, 4, 892677)}
2018-05-21 07:57:05 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:57:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:57:08 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:57:08 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:57:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:57:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:57:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:57:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:57:09 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:57:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:09 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-05-21 07:57:09 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:57:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://carlosmelo.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:57:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:57:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 741,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 57, 9, 577012),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33054720,
 'memusage/startup': 32464896,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 56, 8, 930619)}
2018-05-21 07:57:09 [scrapy.core.engine] INFO: Spider closed (finished)

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:57:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:12 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:57:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://josiasdesouza.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:57:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:57:12 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:57:13 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:57:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:57:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 750,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 57, 13, 77382),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33787904,
 'memusage/startup': 32702464,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 56, 12, 495816)}
2018-05-21 07:57:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:57:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:57:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:57:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:57:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:57:13 [scrapy.core.engine] INFO: Spider opened
2018-05-21 07:57:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-05-21 07:57:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: scrapybot)
2018-05-21 07:57:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 2.7.14 (default, Sep 23 2017, 22:06:14) - [GCC 7.2.0], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-32-generic-i686-with-Ubuntu-17.10-artful
2018-05-21 07:57:16 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}
2018-05-21 07:57:16 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 3 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:57:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-05-21 07:57:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://blogdosakamoto.blogosfera.uol.com.br/>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python2.7/dist-packages/twisted/python/failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python2.7/dist-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
DNSLookupError: DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:57:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-05-21 07:57:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 753,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 5, 21, 10, 57, 16, 850850),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'memusage/max': 33300480,
 'memusage/startup': 32661504,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 5, 21, 10, 56, 16, 364636)}
2018-05-21 07:57:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-05-21 07:57:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-05-21 07:57:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-05-21 07:57:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-05-21 07:57:17 [scrapy.core.engine] INFO: Spider opened

Lendo arquivo de links...


Fim leitura arquivo de links...

2018-05-21 07:57:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-05-21 07:57:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-05-21 07:57:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:57:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:57:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:57:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 1 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
2018-05-21 07:57:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://brasilianismo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: brasilianismo.blogosfera.uol.com.br.
2018-05-21 07:57:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://carlosmelo.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: carlosmelo.blogosfera.uol.com.br.
2018-05-21 07:57:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://josiasdesouza.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: josiasdesouza.blogosfera.uol.com.br.
2018-05-21 07:57:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://blogdosakamoto.blogosfera.uol.com.br/> (failed 2 times): DNS lookup failed: no results for hostname lookup: blogdosakamoto.blogosfera.uol.com.br.
